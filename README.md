    用户请求 → FastAPI接口
        ↓
    Kafka消息队列（异步消息缓冲）
        ↓
    消费者服务：
    - 文档处理与向量化（调用嵌入模型）
    - 向量数据写入Chroma数据库
        ↓
    RAG问答链：
    - 查询请求触发Chroma检索
    - 结合LLM生成答案
        ↓
    返回结果给用户

| 组件                | 技术    | 用途             |
| ----------------- | ----- | -------------- |
| Kafka             | 消息队列  | 解耦请求和文档索引，异步处理 |
| FastAPI           | Web框架 | 提供REST API接口   |
| LangChain         | AI框架  | 拼接向量检索与LLM问答能力 |
| Chroma            | 向量数据库 | 向量存储与语义检索      |
| OpenAI Embeddings | 嵌入模型  | 文本向量化          |
| ChatOpenAI        | LLM服务 | 生成自然语言回答       |



    启动Kafka服务，并创建主题doc_ingest_topic

    启动消费者服务运行kafka_consumer.py（示例代码中的消费者）

    使用kafka_producer.py发送文档消息

    运行FastAPI服务，调用 /rag_query/接口进行问答查询

    | 主题        | 技术理解                        | 实践意义                     |
| --------- | --------------------------- | ------------------------ |
| Kafka消息队列 | 解耦上传与索引处理，避免接口阻塞，提高系统吞吐     | 更适合大规模文档批量处理、异步任务调度      |
| 文本切分策略    | 使用合适大小切块保证上下文连贯，避免截断或冗余     | 好的切分提升向量质量，进而提升检索和回答的准确度 |
| 向量化处理     | 嵌入模型负责抽取语义特征；转换文本数据为向量      | 向量化是实现语义检索和知识匹配的基础       |
| 向量数据库持久化  | 持久存储和高效索引实现海量文档检索           | 保证检索高效、数据不丢失             |
| RAG链集成    | LangChain简化检索与生成组合流程，提升开发效率 | 快速搭建RAG应用核心，研发迭代快        |
| 异步任务      | Kafka等消息队列提供行业级异步可靠数据传递方案   | 避免接口阻塞，提升系统稳定性，适配大规模业务场景 |

| 文件           | 作用               | 说明                       |
| ------------ | ---------------- | ------------------------ |
| utils.py     | Kafka连接工具        | 封装生产者、消费者连接参数            |
| producer.py  | 模拟文档上传Kafka      | 发送文档消息到Kafka，触发消费端索引     |
| ingest.py    | Kafka消费者 + 文档向量化 | 消费文档消息，切分文本，生成向量写入Chroma |
| rag_chain.py | RAG链构建           | 载入向量数据库，构建问答链，使用LLM生成    |
| main.py      | 提供FastAPI查询接口    | 接收用户问题，调用RAG链返回答案和来源     |
